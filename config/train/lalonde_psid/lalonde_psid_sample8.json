{
    "filepaths": {
        "dag_g_formula": "config/dag/lalonde_psid_g_formula_dag.json",
        "dag_ipw": "config/dag/lalonde_psid_ipw_dag.json",
        "dag_aipw": "config/dag/lalonde_psid_aipw_dag.json",
        "config": "config/train/lalonde_psid/lalonde_psid_sample8.json",
        "data_file": "data/lalonde/ldw_psid/ldw_psid.csv",
        "data_train_file": "data/lalonde/ldw_psid/sample8/train_data_8.csv",
        "data_val_file": "data/lalonde/ldw_psid/sample8/val_data_8.csv",
        "data_test_file": "data/lalonde/ldw_psid/sample8/test_data_8.csv",
        "pseudo_ate_file": "src/train/lalonde/lalonde_psid/aipw_grf_pseudo_ate.csv",
        "predictions_g-formula": "experiments/results/lalonde_psid/predictions_g_formula_sample8.csv",
        "predictions_ipw": "experiments/results/lalonde_psid/predictions_ipw_sample8.csv",
        "predictions_aipw": "experiments/results/lalonde_psid/predictions_aipw_sample8.csv"
    },
    "g-formula": {
        "model": {
      "network_width": 512,
      "embedding_dim": 256,
      "feedforward_dim": 1024,
      "num_heads": 1,
      "num_layers": 1,
      "dropout_rate": 0.001,
      "activation": "relu",
      "use_layernorm": false,
      "input_layer_depth": 1,
      "encoder_weight": 0
    },
    "training": {
      "n_epochs": 100,
      "batch_size": 64,
      "learning_rate": 0.001,
      "l2_penalty": 1e-6,
      "dag_attention_mask": true
    }
    },
    "aipw": {
    "model": {
      "network_width": 10,
      "embedding_dim": 10,
      "feedforward_dim": 10,
      "num_heads": 1,
      "num_layers": 1,
      "dropout_rate": 0.1,
      "activation": "relu",
      "use_layernorm": false,
      "input_layer_depth": 1,
      "encoder_weight": 0
    },
    "training": {
      "n_epochs": 23,
      "batch_size": 64,
      "learning_rate": 0.001,
      "l2_penalty": 1e-6,
      "dag_attention_mask": true
    }
  },
     "ipw": {
    "model": {
      "network_width": 10,
      "embedding_dim": 10,
      "feedforward_dim": 20,
      "num_heads": 1,
      "num_layers": 1,
      "dropout_rate": 0.001,
      "activation": "relu",
      "use_layernorm": false,
      "input_layer_depth": 1,
      "encoder_weight": 0
    },
    "training": {
      "n_epochs": 20,
      "batch_size": 64,
      "learning_rate": 0.001,
      "l2_penalty": 1e-6,
      "dag_attention_mask": true
    }
  },
    "random_seed": 42,
    "sample_id": 1
}
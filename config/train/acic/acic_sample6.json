{
    "filepaths": {
        "dag_g_formula": "config/dag/acic_g_formula_dag.json",
        "dag_ipw": "config/dag/acic_ipw_dag.json",
        "dag_aipw": "config/dag/acic_aipw_dag.json",
        "config": "config/train/acic/acic_sample6.json",
        "data_train_file": "data/acic/sample6/data_train_6.csv",
        "data_val_file": "data/acic/sample6/data_val_6.csv",
        "data_test_file": "data/acic/sample6/data_test_6.csv",
        "pseudo_cate_file": "data/acic/sample6/pseudo_ite_6.csv",
        "predictions_g-formula": "experiments/results/acic/predictions_g_formula_sample6.csv",
        "predictions_ipw": "experiments/results/acic/predictions_ipw_sample6.csv",
        "predictions_aipw": "experiments/results/acic/predictions_aipw_sample6.csv"
    },
    "loss_type": {
        "g-formula-loss": "g-formula-loss",
        "ipw-loss": "ipw-loss",
        "cfcv": "aipw-loss"
    },
   "g-formula": {
          "model": {
      "network_width": 20,
      "embedding_dim": 20,
      "feedforward_dim": 40,
      "num_heads": 1,
      "num_layers": 1,
      "dropout_rate": 0.001,
      "activation": "relu",
      "use_layernorm": false,
      "input_layer_depth": 8,
      "encoder_weight": 0
    },
    "training": {
      "n_epochs": 100,
      "batch_size": 64,
      "learning_rate": 0.001,
      "l2_penalty": 1e-6,
      "dag_attention_mask": false
    }
    },
    "aipw": {
    "model": {
      "network_width": 40,
      "embedding_dim": 10,
      "feedforward_dim": 20,
      "num_heads": 1,
      "num_layers": 1,
      "dropout_rate": 0.001,
      "activation": "relu",
      "use_layernorm": false,
      "input_layer_depth": 2,
      "encoder_weight": 0.1
    },
    "training": {
      "n_epochs": 100,
      "batch_size": 64,
      "learning_rate": 0.000001,
      "l2_penalty": 1e-7,
      "dag_attention_mask": true
    }
  },
     "ipw": {
    "model": {
      "network_width": 80,
      "embedding_dim": 40,
      "feedforward_dim": 80,
      "num_heads": 1,
      "num_layers": 1,
      "dropout_rate": 0.001,
      "activation": "relu",
      "use_layernorm": false,
      "input_layer_depth": 4,
      "encoder_weight": 0
    },
    "training": {
      "n_epochs": 10,
      "batch_size": 64,
      "learning_rate": 0.001,
      "l2_penalty": 1e-4,
      "dag_attention_mask": false
    }
  },
    "random_seed": 42,
    "sample_id": 6
}
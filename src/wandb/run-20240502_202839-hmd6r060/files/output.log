embedding.U1.weight torch.Size([2, 512])
embedding.A.weight torch.Size([2, 512])
embedding.Y.weight torch.Size([2, 512])
embedding.X.weight torch.Size([2, 512])
encoder_layer.self_attn.in_proj_weight torch.Size([1536, 512])
encoder_layer.self_attn.in_proj_bias torch.Size([1536])
encoder_layer.self_attn.out_proj.weight torch.Size([512, 512])
encoder_layer.self_attn.out_proj.bias torch.Size([512])
encoder_layer.linear1.weight torch.Size([2048, 512])
encoder_layer.linear1.bias torch.Size([2048])
encoder_layer.linear2.weight torch.Size([512, 2048])
encoder_layer.linear2.bias torch.Size([512])
encoder_layer.norm1.weight torch.Size([512])
encoder_layer.norm1.bias torch.Size([512])
encoder_layer.norm2.weight torch.Size([512])
encoder_layer.norm2.bias torch.Size([512])
encoder.layers.0.self_attn.in_proj_weight torch.Size([1536, 512])
encoder.layers.0.self_attn.in_proj_bias torch.Size([1536])
encoder.layers.0.self_attn.out_proj.weight torch.Size([512, 512])
encoder.layers.0.self_attn.out_proj.bias torch.Size([512])
encoder.layers.0.linear1.weight torch.Size([2048, 512])
encoder.layers.0.linear1.bias torch.Size([2048])
encoder.layers.0.linear2.weight torch.Size([512, 2048])
encoder.layers.0.linear2.bias torch.Size([512])
encoder.layers.0.norm1.weight torch.Size([512])
encoder.layers.0.norm1.bias torch.Size([512])
encoder.layers.0.norm2.weight torch.Size([512])
encoder.layers.0.norm2.bias torch.Size([512])
encoder.layers.1.self_attn.in_proj_weight torch.Size([1536, 512])
encoder.layers.1.self_attn.in_proj_bias torch.Size([1536])
encoder.layers.1.self_attn.out_proj.weight torch.Size([512, 512])
encoder.layers.1.self_attn.out_proj.bias torch.Size([512])
encoder.layers.1.linear1.weight torch.Size([2048, 512])
encoder.layers.1.linear1.bias torch.Size([2048])
encoder.layers.1.linear2.weight torch.Size([512, 2048])
encoder.layers.1.linear2.bias torch.Size([512])
encoder.layers.1.norm1.weight torch.Size([512])
encoder.layers.1.norm1.bias torch.Size([512])
encoder.layers.1.norm2.weight torch.Size([512])
encoder.layers.1.norm2.bias torch.Size([512])
encoder.layers.2.self_attn.in_proj_weight torch.Size([1536, 512])
encoder.layers.2.self_attn.in_proj_bias torch.Size([1536])
encoder.layers.2.self_attn.out_proj.weight torch.Size([512, 512])
encoder.layers.2.self_attn.out_proj.bias torch.Size([512])
encoder.layers.2.linear1.weight torch.Size([2048, 512])
encoder.layers.2.linear1.bias torch.Size([2048])
encoder.layers.2.linear2.weight torch.Size([512, 2048])
encoder.layers.2.linear2.bias torch.Size([512])
encoder.layers.2.norm1.weight torch.Size([512])
encoder.layers.2.norm1.bias torch.Size([512])
encoder.layers.2.norm2.weight torch.Size([512])
encoder.layers.2.norm2.bias torch.Size([512])
output_head.X.weight torch.Size([2, 512])
output_head.X.bias torch.Size([2])
output_head.A.weight torch.Size([2, 512])
output_head.A.bias torch.Size([2])
output_head.Y.weight torch.Size([2, 512])
output_head.Y.bias torch.Size([2])
Traceback (most recent call last):
  File "/Users/manqingliu/Dropbox/Harvard/Research/DAGawareTransformer_NeurIPS/src/u_back_prop.py", line 123, in <module>
    model = ubackprop.back_propagate()
  File "/Users/manqingliu/Dropbox/Harvard/Research/DAGawareTransformer_NeurIPS/src/u_back_prop.py", line 73, in back_propagate
    batch_loss.backward()
  File "/Users/manqingliu/opt/anaconda3/envs/Myenv/lib/python3.10/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/Users/manqingliu/opt/anaconda3/envs/Myenv/lib/python3.10/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn